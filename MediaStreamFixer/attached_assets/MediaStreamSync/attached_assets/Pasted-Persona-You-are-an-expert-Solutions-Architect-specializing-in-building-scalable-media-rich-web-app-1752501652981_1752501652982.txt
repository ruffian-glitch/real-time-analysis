Persona: You are an expert Solutions Architect specializing in building scalable, media-rich web applications with integrated AI and machine learning capabilities. Your expertise lies in designing end-to-end systems that involve video processing, computer vision, and interactive user interfaces.

Core Request:
Design a comprehensive software architecture for a web-based "AI Fitness Coach." This application allows users to upload videos of themselves performing specific fitness drills. The system will analyze these videos, provide detailed performance metrics and visualizations, and offer an interactive chat interface for users to ask questions about their form and performance. The AI should be able to use video playback to answer relevant user queries.

Key Features & User Flow:
Drill Selection & Video Upload:

The user navigates to the upload page.

A clean, intuitive UI prompts the user to select the type of drill they are performing from a predefined list: Push-ups, Squats, Sit-ups, Wall Sit (Chair Hold), Elbow Plank, and Single Leg Balance.

The user selects a drill type and then uploads a video file from their device.

Video Processing & Analysis (Backend):

Once uploaded, the video is sent to the backend for processing.

The system must first ensure the video is in the correct orientation.

Using a computer vision model (e.g., MediaPipe, OpenCV), the system will perform pose estimation to identify key body joints and track their movement throughout the video.

Based on the selected drill type, the backend analyzes the pose data and generates a detailed JSON object containing the full analysis. This JSON is the core output of the processing pipeline and should include:

Overall Metrics: Total reps, total time under tension, form score, etc.

Per-Repetition Data: For exercises like push-ups and squats, an array of objects, where each object represents one rep and contains:

rep_number: The repetition count.

start_frame & end_frame: The start and end frames of that specific rep in the video.

Drill-Specific Angles & Metrics:

For Push-ups: Key body angles and elbow angles at various points in the rep.

For Squats: Key knee and hip angles to measure depth.

(And similar relevant, granular data for all other drills).

Results Dashboard (Frontend):

After processing, the user is directed to a results page.

This page displays the processed video in a player with the correct orientation.

Below the video player, display key summary metrics from the JSON object.

Display interactive graphs and charts visualizing the time-series data from the JSON object.

Interactive AI Chat:

A prominent, circular chat button is fixed on the bottom-right of the results screen.

When the user clicks this button, the UI animates smoothly: the video player and its metrics shift to the left, and a chat interface slides in to occupy the right half.

The user can type questions into the chat.

The AI chat agent, powered by an LLM, interprets the user's question.

Crucially, if the question pertains to a specific moment, the AI should answer not just with text, but also by automatically seeking to and playing the relevant segment of the video.

Technical Stack:
Frontend: React.js, HTML5, CSS3 (consider a framework like Tailwind CSS for styling).

Backend: Python with the Flask web framework.

Video Processing/ML: Libraries such as OpenCV, MediaPipe, or a similar pose estimation framework.

Database: Choose a suitable database for storing user data, video metadata, and the resulting analysis JSON object (e.g., PostgreSQL with JSONB, MongoDB).

Architectural Requirements:
Instruction: Before generating the detailed architecture, first provide a step-by-step plan outlining how you will address each of the following requirements. Once the plan is outlined, proceed with generating the full response immediately without further prompts.

High-Level System Architecture Diagram: A visual representation showing the main components.

Component Breakdown: Detail the key Frontend (React) and Backend (Flask) components and APIs.

Data Flow: Describe the step-by-step flow of data through the system.

Video Processing Pipeline: Detail the sequence of operations in the asynchronous video processing task, emphasizing the generation of the final analysis JSON.

AI Chat Integration (RAG): Explain the Retrieval-Augmented Generation (RAG) approach. Specifically, how will the backend:

Provide the entire analysis JSON object as context to the Large Language Model (LLM) for each user query?

Parse the LLM's response to identify actionable commands?

Translate a conceptual answer (e.g., "Your third squat was your deepest") into a specific command for the frontend (e.g., play_video_segment(start_frame, end_frame)), using the start_frame and end_frame data from the JSON context.

Database Schema: Propose a basic schema, ensuring it can efficiently store the detailed analysis JSON object alongside user and video metadata.